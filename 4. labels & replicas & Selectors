Replica Set is the next generation of Replication Controller. Replication controller is kinda imperative,
but replica sets try to be as declarative as possible.

1.The main difference between a Replica Set and a Replication Controller right now is the selector support.
+--------------------------------------------------+-----------------------------------------------------+
|                   Replica Set                    |               Replication Controller                |
+--------------------------------------------------+-----------------------------------------------------+
| Replica Set supports the new set-based selector. | Replication Controller only supports equality-based |
| This gives more flexibility. for eg:             | selector. for eg:                                   |
|          environment in (production, qa)         |             environment = production                |
|  This selects all resources with key equal to    | This selects all resources with key equal to        |
|  environment and value equal to production or qa | environment and value equal to production           |
+--------------------------------------------------+-----------------------------------------------------+

2.The second thing is the updating the pods.
+-------------------------------------------------------+-----------------------------------------------+
|                      Replica Set                      |            Replication Controller             |
+-------------------------------------------------------+-----------------------------------------------+
| rollout command is used for updating the replica set. | rolling-update command is used for updating   |
| Even though replica set can be used independently,    | the replication controller. This replaces the |
| it is best used along with deployments which          | specified replication controller with a new   |
| makes them declarative.                               | replication controller by updating one pod    |
|                                                       | at a time to use the new PodTemplate.         |
+-------------------------------------------------------+-----------------------------------------------+

metadat + container == pod
in kubernetes typicaly search means selector, if we are searching something is we are selecting something , but we can only select if the labels are set
labels help in resource filtering and mapping
Selectors => two types (1)Equality Based
                       (2) Set-Based Selectopr == more user friendlty


kubectl get pods --show-labels
kubectl get pods --selector "dc=US"      //= equality based selection
kubectl get pods --selector "team=team1" --show-labels        //= equality based selection
kubectl get pods --selector "team=team1,dc=IN" --show-labels  //= equality based selection
kubectl get pods --selector "team!=team1,dc=IN" --show-labels     //= equality based selection

kubectl get pods --selector "dc in (IN)" --show-labels     //Set-Based Selectopr
kubectl get pods --selector "dc in (IN,US)" --show-labels     //Set-Based Selectopr
kubectl get pods --selector "dc notin (IN,US)" --show-labels     //Set-Based Selectopr


first_pod.yml
***************************************************
apiVersion: v1
kind: Pod
metadata:
  name: mypod1
  labels:
    dc: IN
    team: team1

spec:
  containers:
  - name: "myc1"
    image: "httpd"
********************************************
kubectl get pods --show-labels


docs:= https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
****************************************************************************************************************************************
Replicas

Replication controller
kubectl get rc

39: kubectl create -f rc.yml                                      │
operable program or batch file.     │40: kubectl get pods --selector  --show-labels                    │
                                    │41: kubectl get pods  --show-labels                               │
C:\Users\MRUNAL\Documents\kubernetes│42: kubectl get rc                                                │
                                    │43: kubectl create -f rc.yml                                      │
                                    │44: kubectl get pods  --show-labels                               │
                                    │45: kubectl get describe rc                                       │
                                    │46: kubectl describe rc                                           │
                                    │47: kubectl delete pods --all                                     │
                                    │48: kubectl get pods --show-labels


kubectl apply -f rc.yml
The replication controller in Kubernetes is responsible ensures that a specified number of pod replicas are running at any point in time
The replication controller can scale the pods
The replication controller searches & selects the pods with the help of labels 
How to create a replication controller

apiVersion: v1
kind: ReplicationController
metadata:
  name: myrc1
spec:
  replicas: 3
  selector:
    dc: IN
  template:
    metadata:
      name: "mypod"
      labels:
        dc: IN
    spec:
      containers:
      - name: "myc2"
        image: "httpd"
o In the replication controller if the desired state of the container is equal to the current state no pods will be created 
o In the replication controller if the desired state of the container is not equal to the current state  podswill be created

# kubectl apply -f (file name)  // update changes in replication controller

**********************************************************************************************************************************
problems with Replica Set

Suppose we have 3 podsrunning and Version1 and we have to update on Version2,
replica set will delete entire pod of version1 and launch/create pod with version2,
by follwing this our application comes in downtime
for solving this we come with the concept of Deployment

and if we want to move with older versions means roll back then it is not possible with replicaaset

*****************************************************************************************************************************
*****************************************************************************************************************************
***********************************************************************************************************
***********************************************************************************************************
### Node Selector in Kubernetes

Node Selectors in Kubernetes allow you to constrain pods to be scheduled on nodes with specific labels. This is useful for ensuring that certain workloads are only run on appropriate nodes, optimizing resource usage, and maintaining organizational policies.

### Practical Questions and Answers

#### Question 1: Label the node with key=capacity and value=low
**Solution**: Use the following command to label the node:
```sh
kubectl label nodes <node-name> capacity=low
```

#### Question 2: Create a pod and use NodeSelector to schedule it onto the labeled node
**Solution**:
1. Create a YAML file (`pod.yaml`) with the following content:
    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-pod
    spec:
      containers:
      - name: my-container
        image: my-image
      nodeSelector:
        capacity: low
    ```
2. Apply the YAML file using the following command:
    ```sh
    kubectl apply -f pod.yaml
    ```

### Additional Commands

#### Verify Node Labels
To verify the node labels, use the following command:
```sh
kubectl get nodes --show-labels
```
This command displays a list of nodes along with their labels.

### Additional Practical Questions

#### Question 1: Label all nodes in your Kubernetes cluster with a key-value pair "environment=production".
**Solution**: Use the following command to label all nodes:
```sh
kubectl label nodes --all environment=production
```

#### Question 2: How can you remove a label from a node?
**Solution**: Use the `kubectl label` command with the key and node name, followed by a `-` to indicate removal. For example:
```sh
kubectl label node <node-name> capacity-
```

### Summary

Node Selectors in Kubernetes provide a straightforward way to ensure that pods are scheduled on nodes with specific labels. This can help optimize resource utilization and enforce organizational policies.

### Complete Example

#### Step-by-Step Guide

1. **Label a Node**:
    ```sh
    kubectl label nodes node1 capacity=low
    ```
    This command labels the node named `node1` with `capacity=low`.

2. **Create a Pod with NodeSelector**:
    - Create a file named `pod.yaml` with the following content:
        ```yaml
        apiVersion: v1
        kind: Pod
        metadata:
          name: my-pod
        spec:
          containers:
          - name: my-container
            image: nginx
          nodeSelector:
            capacity: low
        ```
    - Apply the configuration:
        ```sh
        kubectl apply -f pod.yaml
        ```

3. **Verify the Node Labels**:
    ```sh
    kubectl get nodes --show-labels
    ```

4. **Label All Nodes in the Cluster**:
    ```sh
    kubectl label nodes --all environment=production
    ```

5. **Remove a Label from a Node**:
    ```sh
    kubectl label node node1 capacity-
    ```

By following these steps, you can effectively use node selectors and labels to control pod scheduling in your Kubernetes cluster.



